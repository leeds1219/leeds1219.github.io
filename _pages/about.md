---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hello! I'm Yikun Liu. I am currently a 2nd-year PhD candidate of <a href="https://mediabrain.sjtu.edu.cn/">MediaBrain</a> at <a href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a>, advised by <a href="https://weidixie.github.io/">Prof.Weidi Xie</a>, <a href="https://sunarker.github.io/index.html">Prof.Jiangchao Yao</a> and <a href="https://cmic.sjtu.edu.cn/wangyanfeng/">Prof.Yanfeng Wang</a>. Previously, I received my B.S. degree from <a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications (BUPT)</a> in june 2023.

My current research interest lies in multi-modal representation learning. Feel free to reach me if you are seeking any form of cooperation.


# ğŸ”¥ News
- *2025.02*: &nbsp;ğŸ‰ğŸ‰ One paper (<a href="https://arxiv.org/abs/2412.01720">LamRA</a>) has been accepted by CVPR.
- *2024.07*: &nbsp;Start internship at Xiaohongshu, Shanghai.
- *2024.02*: &nbsp;ğŸ‰ğŸ‰ One paper (<a href="https://arxiv.org/abs/2403.11074">UFE-AVS</a>) has been accepted by CVPR.
- *2023.08*: &nbsp;ğŸ‰ğŸ‰ One paper (<a href="https://arxiv.org/abs/2306.07272">ZS-CIR</a>) has been accepted by BMVC.

# ğŸ“ Publications 

``CVPR 2025`` [LamRA: Large Multimodal Model as Your Advanced Retrieval Assistant](https://code-kunkun.github.io/LamRA/) [![](https://img.shields.io/github/stars/Code-kunkun/LamRA?style=social&amp;label=Stars)](https://code-kunkun.github.io/LamRA/)<br>
  **Yikun Liu**, Pingan Chen, Jiayin Cai, Xiaolong Jiang, Yao Hu, Jiangchao Yao, Yanfeng Wang, Weidi Xie.

``CVPR 2024`` [Audio-Visual Segmentation via Unlabeled Frame Exploitation](https://jinxiang-liu.github.io/UFE-AVS/) [![](https://img.shields.io/github/stars/jinxiang-liu/UFE-AVS?style=social&label=Stars)](https://github.com/jinxiang-liu/UFE-AVS)<br>
  Jinxiang Liu, **Yikun Liu**, Fei Zhang, Chen Ju, Ya Zhang, Yanfeng Wang.

``BMVC 2023`` [Zero-shot Composed Text-Image Retrieval](https://code-kunkun.github.io/ZS-CIR/) [![](https://img.shields.io/github/stars/Code-kunkun/ZS-CIR?style=social&label=Stars)](https://github.com/Code-kunkun/ZS-CIR)<br>
  **Yikun Liu**, Jiangchao Yao, Yanfeng Wang, Ya Zhang, Weidi Xie.


# ğŸ’» Internships
- *2024.07 - now*, [Xiaohongshu](https://www.xiaohongshu.com
), China.

# ğŸ– Honors and Awards
- *2021.12* China National Scholarship
- *2021.04* Finalist Prize in MCM Competition (Top 1%)